\documentclass[../main.tex]{subfiles}
% !TEX root = ../main.tex

\begin{document}

\section{Section 14.6}

\subsection{Standard Linear Approximation}
For $f(x,y)$ at $(x_0, y_0)$, the Standard Linear Approximation of $f(x,y)$ is 
\begin{equation} 
L(x,y) = f(x_0,y_0) + f_x(x_0,y_0)(x-x_0) + f_y(x_0,y_0)(y-y_0) 
\end{equation}

\subsection{The Error in the Standard Linear Approximation}
If $f$ has continuous first and second partial derivative throughout an open set containing a 
rectangle $R$ centered at $(x_0, y_0)$ and if $M$ is any upper bound for the values of $|f_{xx}|,
|f_{yy}|,$ and $|f_{xy}|$ on $R$, then the error $E(x,y)$ incurred in replacing $f(x,y)$ on $R$ by
its linearizion satisfies the inequality
\begin{equation}
|E(x,y)| \leq \frac12 M(|x-x_0| + |y-y_0|)^2 .
\end{equation}

\subsection{Tangent Plane}
For $f(x,y)$ at $(x_0, y_0)$, the tangent plane of $f(x,y)$ is:
\begin{equation} 
f_x(x_0,y_0)(x-x_0) + f_y(x_0,y_0)(y-y_0) 
\end{equation}
If you have a surface $z = f(x,y)$ at $P(x_0,y_0,z_0)$ use 
\begin{equation}
f_x(x_0,y_0)(x-x_0) + f_y(x_0,y_0)(y-y_0) - (z-z_0) = 0
\end{equation}

\subsection{Normal Line}
The normal line to $f(x,y,z)$ at $P_0 (x_0,y_0,z_0)$ has the following equations:
\begin{align*}
x = x_0 + f_x(P_0)t \\
y = y_0 + f_y(P_0)t \\
z = z_0 + f_z(P_0)t \\
\end{align*}

\newpage
\section{Section 14.7}

\subsection{Definitions of local maximums and minimums}
If $f(x,y)$ is defined on a region $R$ containing the point $(a,b)$, then:
\begin{enumerate}
\item $f(a,b)$ is a \textbf{local maximum} value of $f$ if $f(a,b) \geq f(x,y)$ for all domain
	points $(x,y)$ in an open disk centered at $(a,b)$.
\item $f(a,b)$ is a \textbf{local minimum} value of $f$ if $f(a,b) \leq f(x,y)$ for all domain
	points $(x,y)$ in an open disk centered at $(a,b)$.
\end{enumerate}

\subsection{First Derivative Test for Local Extreme Values}
If all partial derivatives are equal to zero or undefined, then they are critical points.
In order to find local extrema, you must set all partial derivatives to zero and solve the system
of equations.

\subsection{Second Derivative Test for Local Extreme Values}
Let $D$ be the \textbf{discriminant} or \textbf{Hessian} of $f$ so that
\begin{equation*}
D = f_{xx}f_{yy} - f_{xy}^2
\end{equation*}
then 
\begin{enumerate}
\item $f$ has a \textbf{local maximum} at $(a,b)$ if $f_{xx} < 0$ and $D > 0$ at $(a,b)$.
\item $f$ has a \textbf{local minimum} at $(a,b)$ if $f_{xx} > 0$ and $D > 0$ at $(a,b)$.
\item $f$ has a \textbf{saddle point} at $(a,b)$ if $D < 0$ at $(a,b)$.
\item \textbf{the test is inconclusive} at $(a,b)$ if $D = 0$ at $(a,b)$ and another method must be
	in order to determine the behavior at $(a,b)$.
\end{enumerate}

\subsection{Finding Absolute Maxima and Minima on Closed Bounded Regions}
In order to find absolute extrema for $f(x,y)$ on a closed and bounded region $R$, 
\begin{enumerate}
\item \textit{List the interior points of $R$} where $f$ may have local maxima or minima and 
	evaluate $f$ at these points. These are critical points of $f$.
\item \textit{List the boundary points of $R$} where $f$ has local maxima and minima and evaluate 
	$f$ at these points. For every boundary, fix one or more of the variables in order to create a
	function of a single variable and find its local maxima and minima. 
\item \textit{Look through the lists} for the maximum and minimum values of $f$. These will be the
	absolute maximum and minimum values of $f$ on $R$.
\end{enumerate}

\section{Section 14.8}
Using Lagrange multipliers, you can find extreme values of a function whose domain is constrained to
lie within a subset of a plane.

\subsection{Lagrange Multipliers}
If you have two functions, $f(x,y)$ and $g(x,y) = c$, you can find extreme values of $f$ on $g(x,y) = c$ by finding
locations where $\nabla f = \lambda \nabla g$. $\lambda$ is the Lagrange Multiplier. 

\section{Section 14.9}

\subsection{Local Linearization}
The linearization of a function at the point $(x_0, y_0)$ is 
\begin{equation*}
	L(x,y) = f(x_0, y_0) + f_x(x_0, y_0)(x - x_0) + f_y(x_0, y_0)(y - y_0)
\end{equation*}
If $\vect{x_0} = (x_0, y_0)$ and $\vect{x} = (x,y)$,
\begin{equation*}
	L(\vect{x}) = f(\vect{x_0}) + \nabla f \cdot (\vect{x} - \vect{x_0})
\end{equation*}

\subsection{Quadratic Approximation}
The approximation of a function at the point $(x_0, y_0)$ is 
\begin{align*}
	Q(x,y) = &f(x_0, y_0) + f_x(x_0, y_0)(x-x_0) + f_y(x_0, y_0)(y-y_0) \\
	& + \frac12 f_{xx}(x_0, y_0)(x-x_0)^2 + f_{xy}(x_0, y_0)(x-x_0)(y-y_0) + \frac12 f_{yy}(x_0, y_0)(y-y_0)^2
\end{align*}

\subsubsection{Hessian Matrix}
Let $f$ be a function of $(x,y)$
\begin{equation*}
	\vect{H} = 
	\begin{bmatrix}
		f_{xx} & f_{xy} \\
		f_{yx} & f_{yy} 
	\end{bmatrix}
\end{equation*}

\subsubsection{Representing Quadratic Forms with vectors}
\begin{equation*}
ax^2 + 2bxy + cy^2 = 
\begin{bmatrix}
x & y
\end{bmatrix}
\begin{bmatrix}
a & b \\
b & c
\end{bmatrix}
\begin{bmatrix}
x \\
y
\end{bmatrix}
\end{equation*}
You can also let 
\begin{equation*}
\vect{A} = 
\begin{bmatrix}
a & b \\
b & c
\end{bmatrix}
\end{equation*}
and 
\begin{equation*}
\vect{X} = 
\begin{bmatrix}
x \\
y
\end{bmatrix}
\end{equation*}
to get 
\begin{equation*}
ax^2 + 2bxy + cy^2 = \vect{X}^T \vect{A} \vect{X}
\end{equation*}

\subsubsection{Vector form of Quadratic Approximation}
Let $X = \begin{bmatrix} x \\ y \end{bmatrix} $ and $X_0 = \begin{bmatrix} x_0 \\ y_0 \end{bmatrix} $
\begin{equation*}
	Q(X) = f(X_0) + \nabla f \cdot (X - X_0) + \frac12 (X - X_0)^T \vect{H}_{X_0} (X - X_0)
\end{equation*}

\end{document}